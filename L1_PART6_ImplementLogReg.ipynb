{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Introduction\n",
    "\n",
    "**Course:** Big Data And Analytics\n",
    "**Years:** 2023-2024\n",
    "**University:** Polytechnic University of Bari, Italy\n",
    "**Instructor:** Dr. Yashar Deldjoo\n",
    "**Topic:** Training Logistic Regression\n",
    "\n",
    "Welcome to the 'Big Data And Analytics' course, offered by the Polytechnic University of Bari for the academic years 2023-2024. This course is designed to equip students with the fundamental concepts and tools necessary to understand and work with large and complex data sets.\n",
    "\n",
    "We will guide you through the intricacies of data analytics, from theoretical foundations to practical applications. This notebook focuses on the implementation of Gradient Descent, a cornerstone algorithm for optimizing complex models.\n",
    "\n",
    "Feel free to reach out with questions and engage actively in your learning journey. Let's dive into the world of big data together!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yasdel/Big_Data_And_Analytics/blob/main/L1_PART6_ImplementLogReg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "In this lab, you will:\n",
    "- update gradient descent for logistic regression.\n",
    "- explore gradient descent on a familiar data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y, ax):\n",
    "    # Assuming y contains only 0s and 1s\n",
    "    class_0 = y == 0\n",
    "    class_1 = y == 1\n",
    "\n",
    "    # Plot each class with different colors\n",
    "    ax.scatter(X[class_0, 0], X[class_0, 1], c='red', label='Class 0')\n",
    "    ax.scatter(X[class_1, 0], X[class_1, 1], c='blue', label='Class 1')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set \n",
    "Let's start with the same two feature data set used in the decision boundary lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll use a helper function to plot this data. The data points with label $y=1$ are shown as red crosses, while the data points with label $y=0$ are shown as blue circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAENCAYAAADUlXqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAV70lEQVR4nO3df3BddZ3/8ecrbXZjgJUfDVqbpqnArNKioUTA0TK14yoUR3RhRjBbBNGIiAN+3V3X7Yy6XyfqfJkVVmXoxoWhlauMgGjXhf1Ovy7Y+uUL27TbYmm1FqY/UqqU+KXYiZT+eO8f5xSS9Da/uJ9zc9PXY+bOOedzPvfc972QV8/vo4jAzCyFumoXYGaTlwPGzJJxwJhZMg4YM0vGAWNmyThgzCyZQgJGUoOk/5S0QdJTkv6hTJ8FkvZKWp+/vlREbWaWztSCPmc/sDAi9kmqB34h6eGIeHxIv9UR8YGCajKzxAoJmMjO5tuXT9bnL5/hZzbJFbUGg6QpwFrgTOD2iHiiTLd3StoAPAv8dUQ8VWY5nUAnwAknnHDeW97yloRVm9mxrF279vmIaBquj4q+VEDSycCDwGcjYuOA9j8DDuebUYuAf4qIs4ZbVnt7e/T09KQt2MzKkrQ2ItqH61P4UaSIeAF4FLh4SPuLEbEvH38IqJc0rej6zKxyijqK1JSvuSDpdcB7gV8N6fNGScrHz89r6yuiPjNLo6h9MNOBZfl+mDrghxHxU0nXA0TEUuAK4NOSDgJ/BK4MX+ptVtOKOor0JHBumfalA8a/A3yniHrMhjpw4AC9vb289NJL1S5lwmloaKC5uZn6+voxv7ewo0hmE1lvby8nnXQSra2t5FvqBkQEfX199Pb2Mnv27DG/35cKmAEvvfQSp512msNlCEmcdtpp416zc8CY5Rwu5b2W38UBY2bJOGDMJojf/va3XHnllZxxxhmcffbZLFq0iC1btrBt2zbmzp2b5DP379/PRz7yEc4880wuuOACtm3bVtHlO2DMJoCI4MMf/jALFizg6aefZtOmTXzta1/jd7/7XdLPvfPOOznllFPYunUrn/vc5/jCF75Q0eU7YMzGo1SC1laoq8uGpdJrWtwjjzxCfX09119//SttbW1tzJ8/f1C/bdu2MX/+fObNm8e8efN47LHHANi9ezcXXXQRbW1tzJ07l9WrV3Po0CGuueYa5s6dyznnnMOtt9561Of+5Cc/4WMf+xgAV1xxBT/72c+o5OlnPkxtNlalEnR2Qn9/Nr19ezYN0NExrkVu3LiR8847b8R+p59+OitXrqShoYHf/OY3XHXVVfT09PD973+f97///SxZsoRDhw7R39/P+vXr2bVrFxs3Zpf8vfDCC0ctb9euXcycOROAqVOn8vrXv56+vj6mTavMVToOGLOxWrLk1XA5or8/ax9nwIzWgQMHuPHGG1m/fj1Tpkxhy5YtALzjHe/g4x//OAcOHOBDH/oQbW1tvPnNb+aZZ57hs5/9LJdeeinve9/7jlpeubWVSh5N8yaS2Vjt2DG29lGYM2cOa9euHbHfrbfeyhve8AY2bNhAT08PL7/8MgAXXXQRq1atYsaMGSxevJjly5dzyimnsGHDBhYsWMDtt9/OJz7xiaOW19zczM6dOwE4ePAge/fu5dRTTx339xjKAWM2Vi0tY2sfhYULF7J//36++93vvtK2Zs0afv7znw/qt3fvXqZPn05dXR3f+973OHToEADbt2/n9NNP55Of/CTXXXcd69at4/nnn+fw4cNcfvnlfPWrX2XdunVHfe4HP/hBli1bBsD999/PwoULK7oG400ks7Hq6hq8DwagsTFrHydJPPjgg9x888184xvfoKGhgdbWVm677bZB/W644QYuv/xy7rvvPt7znvdwwgknAPDoo49yyy23UF9fz4knnsjy5cvZtWsX1157LYcPHwbg61//+lGfe91117F48WLOPPNMTj31VO69995xf4ey36uWL1j2DaesUjZv3sxb3/rW0b+hVMr2uezYka25dHUl3/9STeV+n9HccMprMGbj0dExqQOlUrwPxsySccCYWTIOGDNLxgFjZsk4YMwsGQeM2QRRjds1rFq1innz5jF16lTuv//+ii/fAWM2AVTrdg0tLS3cfffdfPSjH02yfAeM2ThU+G4NVbtdQ2trK29729uoq0sTBYWcaCepAVgF/Gn+mfdHxJeH9BHwT8AioB+4JiKOvnjCrMoS3K2hardrSK2oM3n3Awvz507XA7+Q9HBEPD6gzyXAWfnrAuCOfGg2oVTxbg0Vv11DaoVsIkVmXz5Zn7+GXgR1GbA87/s4cLKk6UXUZzYWCe7WULXbNaRW2D4YSVMkrQeeA1ZGxBNDuswAdg6Y7s3bhi6nU1KPpJ49e/akK9jsGBLcraFqt2tIrbCAiYhDEdEGNAPnSxp63K3cTSiOutQ7Irojoj0i2puamlKUajasrq7s7gwDvca7Nbxyu4aVK1dyxhlnMGfOHL7yla/wpje9aVC/G264gWXLlnHhhReyZcuWQbdraGtr49xzz+WBBx7gpptuYteuXSxYsIC2tjauueaasrdrWLNmDc3Nzdx333186lOfYs6cOeP/EuVEROEv4MvAXw9p+2fgqgHTvwamD7ec8847L8wqYdOmTWPqf889EbNmRUjZ8J57kpQ1YZT7fYCeGOFvvZA1GElNkk7Ox18HvBf41ZBuK4CrlbkQ2BsRu4uoz2ysOjpg2zY4fDgb+s4N5RV1FGk6sEzSFLLNsh9GxE8lXQ8QEUuBh8gOUW8lO0x9bUG1mVkihQRMRDwJnFumfemA8QA+U0Q9ZuVEhJ9PXUa8hrte+kxeM6ChoYG+vr6KPnRsMogI+vr6aGhoGNf7fctMM7LHd/T29uJTH47W0NBAc3PzuN7rgDED6uvrmT17drXLmHS8iWRmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJklU9SD12ZKekTSZklPSbqpTJ8FkvZKWp+/vlREbRNRqQStrVBXlw1LpWpXZDY+Rd30+yDw+YhYJ+kkYK2klRGxaUi/1RHxgYJqmpBKJejshP7+bHr79mwa/PRAqz2FrMFExO6IWJeP/wHYDMwo4rNrzZIlr4bLEf39WbtZrSl8H4ykVrKnPD5RZvY7JW2Q9LCkOcd4f6ekHkk9k/EZNjt2jK3dbCIrNGAknQg8ANwcES8Omb0OmBURbwe+Dfy43DIiojsi2iOivampKW3BVdDSMrZ2s4mssICRVE8WLqWI+NHQ+RHxYkTsy8cfAuolTSuqvomiqwsaGwe3NTZm7Wa1pqijSALuBDZHxDeP0eeNeT8knZ/X1ldEfRNJRwd0d8OsWSBlw+5u7+C12lTUUaR3AYuBX0pan7f9PdACEBFLgSuAT0s6CPwRuDKO0yeRd3Q4UGxyKCRgIuIXgEbo8x3gO0XUY2bF8Jm8ZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsmaIevDZT0iOSNkt6StJNZfpI0rckbZX0pKR5RdRmxSuVoLUV6uqyYalU7YoslaIevHYQ+HxErJN0ErBW0sqI2DSgzyXAWfnrAuCOfGiTSKkEnZ3Q359Nb9+eTYMfNjcZFbIGExG7I2JdPv4HYDMwY0i3y4DlkXkcOFnS9CLqs+IsWfJquBzR35+12+RT+D4YSa3AucATQ2bNAHYOmO7l6BBCUqekHkk9e/bsSVWmJbJjx9jarbYVGjCSTgQeAG6OiBeHzi7zlqOeTR0R3RHRHhHtTU1NKcq0hFpaxtZuta2wgJFUTxYupYj4UZkuvcDMAdPNwLNF1GbF6eqCxsbBbY2NWbtNPkUdRRJwJ7A5Ir55jG4rgKvzo0kXAnsjYncR9VlxOjqguxtmzQIpG3Z3ewfvZFXUUaR3AYuBX0pan7f9PdACEBFLgYeARcBWoB+4tqDarGAdHQ6U40UhARMRv6D8PpaBfQL4TBH1mFkxfCavmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS+Y1BYykqytViJlNPqM6D0bS2eWagU8ByytakZlNGqM90e5x4H6OPlluVmXLMbPJZLQBsxn4m4joG9go6d8qX5KZTRbD7oORNCUf/QvghaHzI+LSFEWZ2eQw0k7ef5d0YkS8GBGHCqnIzCaNkQJmPfB/Jb3pSIOkiyStTluWmU0Gw+6DiYi/kfQ0Wch8EbgOOAe4pYjizKy2jeY8mMeAF4ES2T1zZ0fEPyatyswmhZF28v4IeJTsVpd/CbwfWJi+LDObDEY6TP0b4BMR8XsASc8AKyS1RsTtyaszs5o27BpMRHzhSLjk078E3g18MnVhZlb7xnwtUkTsAuYnqMXMJplxXeyYP53RzGxYvl2DmSXjgDGzZIp68Npdkp6TtPEY8xdI2itpff76UhF1mVlaRa3B3A1cPEKf1RHRlr/+ZwE1jV6pBK2tUFeXDUulaldkVhOKevDaKkmtRXxWxZVK0NkJ/f3Z9Pbt2TT48YRmI5hI+2DeKWmDpIclzal2Ma9YsuTVcDmivz9rN7NhFfVs6pGsA2ZFxD5Ji4AfA2eV6yipE+gEaGlpSV/Zjh1jazezV0yINZj8fjP78vGHgHpJ047Rtzsi2iOivampKX1xxwqxIsLNrMZNiICR9EZJysfPJ6urb/h3FaSrCxobB7c1NmbtZjasQjaRJP0AWABMk9QLfBmoB4iIpcAVwKclHQT+CFwZEVFEbSM6siN3yZJss6ilJQsX7+A1G5Emyt/xeLS3t0dPT0+1yzA7LklaGxHtw/WZEJtIZjY5OWDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyhQSMpLskPSdp4zHmS9K3JG2V9KSkeUXUNWGVStDaCnV12bBUqnZFZuNS1BrM3cDFw8y/hOxh92eRPdj+jgJqmphKJejshO3bISIbdnY6ZKwmFRIwEbEK+P0wXS4DlkfmceBkSdOLqG3CWbIE+vsHt/X3Z+1mNWai7IOZAewcMN2btx1FUqekHkk9e/bsKaS4Qu3YMbZ2swlsogSMyrSVfWh2RHRHRHtEtDc1NSUuqwpaWsbWbjaBTZSA6QVmDphuBp6tUi3V1dUFjY2D2xobs3azGjNRAmYFcHV+NOlCYG9E7K52UVXR0QHd3TBrFkjZsLs7azerMVOL+BBJPwAWANMk9QJfBuoBImIp8BCwCNgK9APXFlHXhNXR4UCxSaGQgImIq0aYH8BniqjFzIozUTaRzGwScsCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJVNYwEi6WNKvJW2V9Hdl5i+QtFfS+vz1paJqO+6VStDaCnV12bBUqnZFNc0/56uKevDaFOB24C/IHhO7RtKKiNg0pOvqiPhAETVZrlSCzk7o78+mt2/PpsEPfxsH/5yDFbUGcz6wNSKeiYiXgXuBywr6bBvOkiWv/jUc0d+ftduY+eccrKiAmQHsHDDdm7cN9U5JGyQ9LGlOuQVJ6pTUI6lnz549KWo9vuzYMbZ2G5Z/zsGKChiVaYsh0+uAWRHxduDbwI/LLSgiuiOiPSLam5qaKlzmcailZWztNiz/nIMVFTC9wMwB083AswM7RMSLEbEvH38IqJc0raD6jl9dXdDYOLitsTFrtzHzzzlYUQGzBjhL0mxJfwJcCawY2EHSGyUpHz8/r62voPqOXx0d0N0Ns2aBlA27u4/PPZIV4J9zMEUM3VJJ9EHSIuA2YApwV0R0SboeICKWSroR+DRwEPgj8D8i4rHhltne3h49PT2JKzezciStjYj2YfsUFTApOGDMqmc0AeMzec0sGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTKFBYykiyX9WtJWSX9XZr4kfSuf/6SkeUXVZmZpFBIwkqYAtwOXAGcDV0k6e0i3S4Cz8lcncEcRtZlZOkWtwZwPbI2IZyLiZeBe4LIhfS4DlkfmceBkSdMLqs/MEpha0OfMAHYOmO4FLhhFnxnA7oGdJHWSreEA7Je0sbKlTijTgOerXURC/n617c9H6lBUwKhM29Bn1o6mDxHRDXQDSOoZ6dGVtczfr7YdD99vpD5FbSL1AjMHTDcDz46jj5nVkKICZg1wlqTZkv4EuBJYMaTPCuDq/GjShcDeiNg9dEFmVjsK2USKiIOSbgT+NzAFuCsinpJ0fT5/KfAQsAjYCvQD145i0d2JSp4o/P1q23H//RRx1G4OM7OK8Jm8ZpaMA8bMkqnZgBnp0oNaJukuSc9NxnN8JM2U9IikzZKeknRTtWuqJEkNkv5T0ob8+/1DtWtKQdIUSf8l6afD9avJgBnlpQe17G7g4moXkchB4PMR8VbgQuAzk+y/3X5gYUS8HWgDLs6Pik42NwGbR+pUkwHD6C49qFkRsQr4fbXrSCEidkfEunz8D2T/k86oblWVk1/qsi+frM9fk+pIiqRm4FLgX0bqW6sBc6zLCqyGSGoFzgWeqG4llZVvPqwHngNWRsSk+n7AbcDfAodH6lirATOqywps4pJ0IvAAcHNEvFjteiopIg5FRBvZ2ejnS5pb7ZoqRdIHgOciYu1o+tdqwPiyghomqZ4sXEoR8aNq15NKRLwAPMrk2p/2LuCDkraR7ZpYKOmeY3Wu1YAZzaUHNgFJEnAnsDkivlnteipNUpOkk/Px1wHvBX5V3aoqJyK+GBHNEdFK9nf3HxHxV8fqX5MBExEHgSOXHmwGfhgRT1W3qsqR9APg/wF/LqlX0nXVrqmC3gUsJvuXb33+WlTtoipoOvCIpCfJ/iFcGRHDHsqdzHypgJklU5NrMGZWGxwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGCsEJL+l6QHB0zfIuln+Vm9Nkn5PBgrhKTTgKeBBeS3aQDeHRF7q1mXpeWAscJI+grwl8DrycJlZ97eBVwE/A64OiL6q1akVZQ3kaxI/wWcA3xxQLjMBc6IiPnA/wE+XsX6rMIcMFYISecAdwDLGBwi84GH8/GHgXcXXJol5ICx5CTNAP4VuB64AThH0oJ89inAkf0we4FTCy/QknHAWFKS/ozsoXrfjIgV+f6VW4CuvMv/J9snQz6clLcKPV55J69VVb7p9MWI+KikTuBPI+Lb1a7LKqOQR8eaHUtE/FLSdkmrye5he3W1a7LK8RqMmSXjfTBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZP4bGX82mKYSCwcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "plot_data(X_train, y_train, ax)\n",
    "\n",
    "ax.axis([0, 4, 0, 3.5])\n",
    "ax.set_ylabel('$x_1$', fontsize=12)\n",
    "ax.set_xlabel('$x_0$', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Gradient Descent\n",
    "\n",
    "Recall the gradient descent algorithm utilizes the gradient calculation:\n",
    "$$\\begin{align*}\n",
    "&\\text{repeat until convergence:} \\; \\lbrace \\\\\n",
    "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1} \\\\ \n",
    "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\\\\n",
    "&\\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "Where each iteration performs simultaneous updates on $w_j$ for all $j$, where\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{2} \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3} \n",
    "\\end{align*}$$\n",
    "\n",
    "* m is the number of training examples in the data set      \n",
    "* $f_{\\mathbf{w},b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target\n",
    "* For a logistic regression model  \n",
    "    $z = \\mathbf{w} \\cdot \\mathbf{x} + b$  \n",
    "    $f_{\\mathbf{w},b}(x) = g(z)$  \n",
    "    where $g(z)$ is the sigmoid function:  \n",
    "    $g(z) = \\frac{1}{1+e^{-z}}$   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Implementation\n",
    "The gradient descent algorithm implementation has two components: \n",
    "- The loop implementing equation (1) above. This is `gradient_descent` below and is generally provided to you in optional and practice labs.\n",
    "- The calculation of the current gradient, equations (2,3) above. This is `compute_gradient_logistic` below. You will be asked to implement this week's practice lab.\n",
    "\n",
    "#### Calculating the Gradient, Code Description\n",
    "Implements equation (2),(3) above for all $w_j$ and $b$.\n",
    "There are many ways to implement this. Outlined below is this:\n",
    "- initialize variables to accumulate `dj_dw` and `dj_db`\n",
    "- for each example\n",
    "    - calculate the error for that example $g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b) - \\mathbf{y}^{(i)}$\n",
    "    - for each input value $x_{j}^{(i)}$ in this example,  \n",
    "        - multiply the error by the input  $x_{j}^{(i)}$, and add to the corresponding element of `dj_dw`. (equation 2 above)\n",
    "    - add the error to `dj_db` (equation 3 above)\n",
    "\n",
    "- divide `dj_db` and `dj_dw` by total number of examples (m)\n",
    "- note that $\\mathbf{x}^{(i)}$ in numpy `X[i,:]` or `X[i]`  and $x_{j}^{(i)}$ is `X[i,j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X (ndarray (m,n): Data, m examples with n features\n",
    "      y (ndarray (m,)): target values\n",
    "      w (ndarray (n,)): model parameters  \n",
    "      b (scalar)      : model parameter\n",
    "    Returns\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar)      : The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    dj_dw = np.zeros((n,))                           #(n,)\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i],w) + b)          #(n,)(n,)=scalar\n",
    "        err_i  = f_wb_i  - y[i]                       #scalar\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err_i * X[i,j]      #scalar\n",
    "        dj_db = dj_db + err_i\n",
    "    dj_dw = dj_dw/m                                   #(n,)\n",
    "    dj_db = dj_db/m                                   #scalar\n",
    "        \n",
    "    return dj_db, dj_dw  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the implementation of the gradient function using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.49861806546328574\n",
      "dj_dw: [0.498333393278696, 0.49883942983996693]\n"
     ]
    }
   ],
   "source": [
    "X_tmp = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_tmp = np.array([0, 0, 0, 1, 1, 1])\n",
    "w_tmp = np.array([2.,3.])\n",
    "b_tmp = 1.\n",
    "dj_db_tmp, dj_dw_tmp = compute_gradient_logistic(X_tmp, y_tmp, w_tmp, b_tmp)\n",
    "print(f\"dj_db: {dj_db_tmp}\" )\n",
    "print(f\"dj_dw: {dj_dw_tmp.tolist()}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "``` \n",
    "dj_db: 0.49861806546328574\n",
    "dj_dw: [0.498333393278696, 0.49883942983996693]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent Code \n",
    "The code implementing equation (1) above is implemented below. Take a moment to locate and compare the functions in the routine to the equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(X, y, w, b):\n",
    "    m = X.shape[0]\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb_i = sigmoid(np.dot(X[i], w) + b)\n",
    "        cost = -y[i] * np.log(f_wb_i) - (1 - y[i]) * np.log(1 - f_wb_i)\n",
    "        total_cost += cost\n",
    "\n",
    "    return total_cost / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n)   : Data, m examples with n features\n",
    "      y (ndarray (m,))   : target values\n",
    "      w_in (ndarray (n,)): Initial values of model parameters  \n",
    "      b_in (scalar)      : Initial values of model parameter\n",
    "      alpha (float)      : Learning rate\n",
    "      num_iters (scalar) : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,))   : Updated values of parameters\n",
    "      b (scalar)         : Updated value of parameter \n",
    "    \"\"\"\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = compute_gradient_logistic(X, y, w, b)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( compute_cost_logistic(X, y, w, b) )\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
    "        \n",
    "    return w, b, J_history         #return final w,b and J history for graphing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run gradient descent on our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 0.684610468560574   \n",
      "Iteration 1000: Cost 0.1590977666870456   \n",
      "Iteration 2000: Cost 0.08460064176930081   \n",
      "Iteration 3000: Cost 0.05705327279402531   \n",
      "Iteration 4000: Cost 0.042907594216820076   \n",
      "Iteration 5000: Cost 0.034338477298845684   \n",
      "Iteration 6000: Cost 0.028603798022120097   \n",
      "Iteration 7000: Cost 0.024501569608793   \n",
      "Iteration 8000: Cost 0.02142370332569295   \n",
      "Iteration 9000: Cost 0.019030137124109114   \n",
      "\n",
      "updated parameters: w:[5.28123029 5.07815608], b:-14.222409982019837\n"
     ]
    }
   ],
   "source": [
    "w_tmp  = np.zeros_like(X_train[0])\n",
    "b_tmp  = 0.\n",
    "alph = 0.1\n",
    "iters = 10000\n",
    "\n",
    "w_out, b_out, _ = gradient_descent(X_train, y_train, w_tmp, b_tmp, alph, iters) \n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_prob(ax, w, b):\n",
    "    # Create a mesh to plot in\n",
    "    x_min, x_max = 0, 4\n",
    "    y_min, y_max = 0, 3.5\n",
    "    h = .01  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Calculate the probabilities for each point in the mesh\n",
    "    Z = sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], w) + b)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour and margins\n",
    "    ax.contourf(xx, yy, Z, levels=[0, 0.5, 1], cmap=plt.cm.RdBu, alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot the results of gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dlc = {\"dlblue\": \"#1f77b4\"}  # Replace \"#1f77b4\" with the actual color code you want\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,4))\n",
    "# plot the probability \n",
    "plt_prob(ax, w_out, b_out)\n",
    "\n",
    "# Plot the original data\n",
    "ax.set_ylabel(r'$x_1$')\n",
    "ax.set_xlabel(r'$x_0$')   \n",
    "ax.axis([0, 4, 0, 3.5])\n",
    "plot_data(X_train,y_train,ax)\n",
    "\n",
    "# Plot the decision boundary\n",
    "x0 = -b_out/w_out[0]\n",
    "x1 = -b_out/w_out[1]\n",
    "ax.plot([0,x0],[x1,0], c=dlc[\"dlblue\"], lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above:\n",
    " - the shading reflects the probability y=1 (result prior to decision boundary)\n",
    " - the decision boundary is the line at which the probability = 0.5\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "You have:\n",
    "- examined the formulas and implementation of calculating the gradient for logistic regression\n",
    "- utilized those routines in\n",
    "    - exploring a single variable data set\n",
    "    - exploring a two-variable data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
